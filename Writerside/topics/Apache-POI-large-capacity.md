# Apache-POI를 활요한 대용량 엑셀 다운로드 구현

회사 정산 팀에서 화면으로 확인할 수 있는  대용량 데이터를 엑셀로 다운받을 수 있도록 기능을 제공해달라고
기존의 엑셀 다운로드 기능을 보완해 **대용량** 엑셀 다운로드 기능을 구현해야 했습니다.
이를 위해
1. XSSF에서 SXSSF로 수정하고
2. 쿼리 실행 개선했던<br/>
경험을 공유합니다.

## 히스토리
기존에 엑셀 다운로드 기능 구현을 위해 사용하던 공통 함수는 Apache-POI 라이브러리의 XSSF를 이용해 개발되어 있었습니다.<br/>
XSSF는 jxls 표현식으로 작성된 템플릿을 읽고 데이터에 변수를 할당하는 방식으로 엑셀 다운로드 기능을 구현합니다.<br/>
스타일도 적용할 수 있고 손 쉽게 구현할 수 있다는 장점이 있지만 대용량 데이터를 처리하는데 적합하지 않아 개선이 필요했습니다.

> **XSSF가 대용량 데이터 처리에 적합하지 않은 이유**
> 
> 1. 템플릿을 읽는 데 오랜 시간이 소요되며
> 2. 제한된 힙 메모리만을 사용해 가용 메모리를 초과할 위험이 있고
> 3. 데이터를 읽고 쓰는 동안 메모리를 계속 점유한다는 점이었습니다.
>
{style="warning"}

### 요구사항
1. API 응답으로 엑셀 파일을 보낸다.
2. 엑셀 파일은 여러 테이블에 걸쳐 저장되어 있는 수십만 건의 데이터를 조회해 파일로 출력한 결과물이다.
3. 데이터는 분리된 서버에서 가져온다.

3. 또한, 데이터는 MSA로 분리된 다른 서버에서 가져와야 했는데, 데이터 양이 많아 쿼리 실행 중 세션 시간이 초과되는 이슈가 있었습니다.
2. OOM(Out Of Memory) 방지

### 이슈

- XSSF는 jxls 표현식으로 작성된 템플릿을 읽고 데이터에 변수를 할당하는 방식입니다. 하지만 이 방식에는 몇 가지 문제점이 있었습니다. 1) 템플릿을 읽는 데 오랜 시간이 소요되며, 2) 제한된 힙 메모리만을 사용해 가용 메모리를 초과할 위험이 있고, 3) 데이터를 읽고 쓰는 동안 메모리를 계속 점유한다는 점이었습니다.
- 그 결과, 수십만 건의 데이터를 처리하는 과정에서 OOM(Out Of Memory) 오류가 발생했습니다.
- 또한, 데이터는 MSA로 분리된 다른 서버에서 가져와야 했는데, 데이터 양이 많아 쿼리 실행 중 연결 시간이 초과되어 통신이 끊어지는 문제도 발생했습니다.
- 이를 해결하기 위해 다음과 같은 조치를 취했습니다. 1) XSSF를 SXSSF로 전환하고, 2) 일정량의 데이터를 쓰고 나면 메모리를 비우도록 설정했으며, 3) 데이터를 한 번에 불러오는 대신 여러 번 나눠서 불러오도록 로직을 변경했습니다.
- SXSSF는 read 기능을 지원하지 않아 템플릿을 적용할 수 없기 때문에 개발 공수가 더 들었습니다. 하지만 이미 기록된 데이터는 메모리에서 해제되기 때문에, 메모리를 효율적으로 사용할 수 있다는 장점이 있습니다.
- 템플릿을 사용하는 대신, 데이터를 정확하게 엑셀 파일에 옮기는 것이 정산 팀의 요구에 부합한다고 판단했습니다. 결과적으로 템플릿을 버리고 정산 팀이 요청한 대로 기능을 추가할 수 있었습니다.

> **Highlight important information**
>
> You can change the element to *tip* or *warning* by renaming the style attribute below.
>
{style="note"}

## Before you start

It is good practice to list the prerequisites that are required or recommended.

Make sure that:
- First prerequisite
- Second prerequisite

## How to perform a task

Some introductory information.

1. Step with a code block

   ```bash
    run this --that
   ```

2. Step with a [link](https://www.jetbrains.com)

3. Step with a list.
   - List item
   - List item
   - List item
- PostgreSQL에서 `OFFSET`을 증가시키며 데이터를 불러오는 방식과 PK(Primary Key)를 기준으로 데이터를 불러오는 방식은 성능 면에서 차이가 있습니다. 두 방식은 각각의 동작 방식과 특징으로 인해 성능이 달라집니다.

### 1. **OFFSET을 사용한 페이징**
`OFFSET`을 사용하면 쿼리에서 특정 수의 행을 건너뛴 후 다음 행을 반환합니다. 예를 들어, 1000개의 레코드를 조회할 때 `OFFSET 500 LIMIT 100`을 사용하면 500개의 행을 건너뛰고 100개의 행을 반환합니다.

**장점:**
- 간단하게 페이지네이션을 구현할 수 있습니다.
- 주로 페이징 UI와 같이 순서대로 데이터를 가져와야 하는 상황에서 사용됩니다.

**단점:**
- `OFFSET`은 데이터가 많을수록 성능이 저하됩니다. `OFFSET N`을 사용하면 PostgreSQL은 처음부터 N개의 행을 읽고 그 후에 버리므로 N이 클수록 쿼리가 느려집니다.
- 인덱스가 제대로 활용되지 않으면 성능에 큰 영향을 미칩니다.

**성능 문제:**
- `OFFSET`이 증가할수록 데이터베이스가 더 많은 데이터를 스캔하고 버리기 때문에 비용이 증가합니다. 결국 테이블의 크기가 커질수록 느려집니다.

### 2. **PK(Primary Key)를 기준으로 페이징**
PK(또는 다른 인덱스가 적용된 컬럼)를 기준으로 데이터를 가져오는 방식은 일반적으로 더 효율적입니다. 예를 들어, `WHERE id > last_id LIMIT 100`과 같이 PK를 사용해 데이터 범위를 지정하는 방식입니다.

**장점:**
- 인덱스가 있는 컬럼을 사용하기 때문에 성능이 더 좋습니다.
- `OFFSET`과 달리 이미 가져온 데이터를 다시 읽을 필요가 없으므로 빠르게 다음 페이지를 로드할 수 있습니다.
- 테이블의 크기가 커지더라도 일정한 성능을 유지합니다.

**단점:**
- 순차적으로 증가하는 PK가 있어야 합니다. 순서대로 정렬된 값이 필요합니다.
- 사용자 경험에 맞춰서 이전 페이지로 돌아가는 등의 기능을 구현할 때 복잡도가 다소 증가할 수 있습니다.

### 성능 비교
- **데이터 양이 적을 때**: `OFFSET` 방식과 PK 기준 방식의 성능 차이는 크게 나지 않습니다. 다만, 데이터 양이 많아지기 시작하면 차이가 커집니다.
- **데이터 양이 많을 때**: PK를 기준으로 데이터를 가져오는 방식이 훨씬 효율적입니다. 특히 데이터가 수십만 건을 넘는 경우, `OFFSET` 방식은 스캔 비용 때문에 성능이 크게 저하되지만, PK 방식은 인덱스를 사용해 훨씬 빠르게 데이터를 가져옵니다.

### 요약
- **작은 테이블**: `OFFSET` 방식이 직관적이고 구현이 간단합니다.
- **큰 테이블**: PK를 사용한 방식이 성능에 유리합니다. 데이터 양이 많아질수록 PK를 기준으로 페이징을 구현하는 것이 더 좋은 선택입니다.